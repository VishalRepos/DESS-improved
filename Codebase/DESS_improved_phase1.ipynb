{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# D2E2S Phase 1 Training â€” All Datasets\n",
        "\n",
        "Training notebook for the DESS (D2E2S) ABSA model with Phase 1 improvements:\n",
        "- Differential learning rates (transformer 1e-5, task heads 3e-4)\n",
        "- Reduced batch_loss weight (2.0 instead of 10.0)\n",
        "- Focal loss for sentiment classification\n",
        "- Cosine annealing LR schedule\n",
        "\n",
        "Target: Kaggle P100 (16GB) with `deberta-v3-base` and batch_size 16."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "print(os.getcwd())\n",
        "os.chdir('/kaggle/working')\n",
        "print('Working directory:', os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "print(f'PyTorch version: {torch.__version__}')\n",
        "print(f'CUDA available: {torch.cuda.is_available()}')\n",
        "if torch.cuda.is_available():\n",
        "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
        "    print(f'GPU Memory: {torch.cuda.get_device_properties(0).total_mem / 1024**3:.1f} GB')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Download DeBERTa-v3-base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "model_name = 'microsoft/deberta-v3-base'\n",
        "save_path = './deberta-v3-base'\n",
        "\n",
        "if not os.path.exists(os.path.join(save_path, 'config.json')):\n",
        "    print(f'Downloading {model_name}...')\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModel.from_pretrained(model_name)\n",
        "    tokenizer.save_pretrained(save_path)\n",
        "    model.save_pretrained(save_path)\n",
        "    del model, tokenizer\n",
        "    torch.cuda.empty_cache()\n",
        "    print('Download complete.')\n",
        "else:\n",
        "    print('DeBERTa model already downloaded.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Training Configuration\n",
        "\n",
        "Common flags for all datasets with Phase 1 improvements enabled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "COMMON_FLAGS = (\n",
        "    '--seed 42 '\n",
        "    '--max_span_size 8 '\n",
        "    '--batch_size 16 '\n",
        "    '--epochs 120 '\n",
        "    '--pretrained_deberta_name microsoft/deberta-v3-base '\n",
        "    '--deberta_feature_dim 768 '\n",
        "    '--hidden_dim 384 '\n",
        "    '--emb_dim 768 '\n",
        "    '--use_enhanced_semgcn '\n",
        "    '--use_differential_lr '\n",
        "    '--transformer_lr 1e-5 '\n",
        "    '--task_lr 3e-4 '\n",
        "    '--batch_loss_weight 2.0 '\n",
        "    '--use_focal_loss '\n",
        "    '--focal_gamma 2.0 '\n",
        "    '--use_cosine_schedule'\n",
        ")\n",
        "\n",
        "DATASETS = ['14res', '14lap', '15res', '16res']\n",
        "\n",
        "print('Phase 1 training flags:')\n",
        "print(COMMON_FLAGS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Train All Datasets\n",
        "\n",
        "Each dataset trains for 120 epochs. Results are saved to `log/{dataset}/{timestamp}/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 14res (SemEval 2014 Restaurant) ---\n",
        "!python train.py --dataset 14res {COMMON_FLAGS}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 14lap (SemEval 2014 Laptop) ---\n",
        "!python train.py --dataset 14lap {COMMON_FLAGS}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 15res (SemEval 2015 Restaurant) ---\n",
        "!python train.py --dataset 15res {COMMON_FLAGS}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 16res (SemEval 2016 Restaurant) ---\n",
        "!python train.py --dataset 16res {COMMON_FLAGS}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Review Results\n",
        "\n",
        "Check the latest result files for each dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "for ds in DATASETS:\n",
        "    print(f'\\n{\"=\"*60}')\n",
        "    print(f'Dataset: {ds}')\n",
        "    print(f'{\"=\"*60}')\n",
        "    result_dirs = sorted(glob.glob(f'log/{ds}/*/result/result8.txt'))\n",
        "    if result_dirs:\n",
        "        latest = result_dirs[-1]\n",
        "        print(f'Latest result: {latest}')\n",
        "        with open(latest) as f:\n",
        "            print(f.read())\n",
        "    else:\n",
        "        print('No results found yet.')"
      ]
    }
  ]
}