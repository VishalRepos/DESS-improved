# üéØ Strategy to Reach 80% Triplet F1 Score

**Current Performance**: 77.14% Triplet F1  
**Target**: 80% Triplet F1  
**Gap**: +2.86% improvement needed  
**Date**: January 5, 2026

---

## üìä Current Architecture Analysis

### Strengths ‚úÖ
1. **Enhanced Semantic GCN** - Working well (+1.39% improvement)
2. **DeBERTa-v3-base** - Good contextualized embeddings
3. **Stable training** - Low variance, consistent results
4. **Efficient memory usage** - Fits on P100 GPU

### Bottlenecks üî¥
1. **TIN Fusion Module** - Simple concatenation + LSTM, may lose information
2. **Entity-Sentiment Pairing** - Fixed classifier, no learned interaction
3. **Syntactic GCN** - Underutilized, hurts when combined
4. **Single model** - No ensemble or multi-model approach
5. **Limited context** - No cross-sentence or document-level features
6. **Static embeddings** - Size embeddings are simple, not contextual

---

## üöÄ Improvement Strategies (Prioritized by Impact)

### **TIER 1: High Impact, Low Risk** (Expected: +1.5-2%)

#### 1. **Contrastive Learning for Entity-Opinion Pairing** ‚≠ê‚≠ê‚≠ê
**Problem**: Current classifier treats all entity-opinion pairs independently  
**Solution**: Add contrastive loss to learn better entity-opinion representations

**Implementation**:
```python
class ContrastivePairEncoder(nn.Module):
    def __init__(self, hidden_dim):
        self.entity_encoder = nn.Linear(hidden_dim, hidden_dim)
        self.opinion_encoder = nn.Linear(hidden_dim, hidden_dim)
        self.temperature = 0.07
    
    def forward(self, entity_repr, opinion_repr):
        # Project to same space
        entity_proj = F.normalize(self.entity_encoder(entity_repr), dim=-1)
        opinion_proj = F.normalize(self.opinion_encoder(opinion_repr), dim=-1)
        
        # Contrastive loss: pull positive pairs together, push negatives apart
        similarity = torch.matmul(entity_proj, opinion_proj.T) / self.temperature
        labels = torch.arange(len(entity_proj)).to(similarity.device)
        loss = F.cross_entropy(similarity, labels)
        return loss
```

**Expected Gain**: +0.5-0.8%  
**Effort**: Medium  
**Risk**: Low

---

#### 2. **Span Boundary Refinement Module** ‚≠ê‚≠ê‚≠ê
**Problem**: Entity/opinion span boundaries may be imprecise  
**Solution**: Add boundary-aware attention to refine span representations

**Implementation**:
```python
class BoundaryRefinement(nn.Module):
    def __init__(self, hidden_dim):
        self.start_attention = nn.Linear(hidden_dim, 1)
        self.end_attention = nn.Linear(hidden_dim, 1)
        self.boundary_lstm = nn.LSTM(hidden_dim, hidden_dim//2, bidirectional=True)
    
    def forward(self, span_repr, context):
        # Boundary-aware LSTM
        boundary_features, _ = self.boundary_lstm(context)
        
        # Soft attention for start/end
        start_scores = self.start_attention(boundary_features).squeeze(-1)
        end_scores = self.end_attention(boundary_features).squeeze(-1)
        
        start_weights = F.softmax(start_scores, dim=-1)
        end_weights = F.softmax(end_scores, dim=-1)
        
        # Refined span representation
        refined_span = (start_weights.unsqueeze(-1) * boundary_features).sum(1) + \
                       (end_weights.unsqueeze(-1) * boundary_features).sum(1)
        return refined_span
```

**Expected Gain**: +0.4-0.6%  
**Effort**: Medium  
**Risk**: Low

---

#### 3. **Improved TIN Fusion with Cross-Attention** ‚≠ê‚≠ê‚≠ê
**Problem**: Current TIN uses simple concatenation, loses fine-grained interactions  
**Solution**: Replace with cross-attention between semantic and syntactic features

**Implementation**:
```python
class CrossAttentionFusion(nn.Module):
    def __init__(self, hidden_dim, num_heads=8):
        self.sem_to_syn = nn.MultiheadAttention(hidden_dim, num_heads)
        self.syn_to_sem = nn.MultiheadAttention(hidden_dim, num_heads)
        self.gate = nn.Linear(hidden_dim * 2, hidden_dim)
        self.layer_norm = nn.LayerNorm(hidden_dim)
    
    def forward(self, sem_features, syn_features):
        # Cross-attend: semantic queries syntactic
        sem_attended, _ = self.sem_to_syn(sem_features, syn_features, syn_features)
        
        # Cross-attend: syntactic queries semantic
        syn_attended, _ = self.syn_to_sem(syn_features, sem_features, sem_features)
        
        # Gated fusion
        concat = torch.cat([sem_attended, syn_attended], dim=-1)
        gate = torch.sigmoid(self.gate(concat))
        fused = gate * sem_attended + (1 - gate) * syn_attended
        
        return self.layer_norm(fused + sem_features)  # Residual
```

**Expected Gain**: +0.5-0.7%  
**Effort**: Medium  
**Risk**: Medium (may need tuning)

---

#### 4. **Sentiment-Aware Entity Representations** ‚≠ê‚≠ê
**Problem**: Entity representations don't consider sentiment context  
**Solution**: Add sentiment prototype learning

**Implementation**:
```python
class SentimentPrototypes(nn.Module):
    def __init__(self, hidden_dim, num_sentiments=3):
        # Learnable sentiment prototypes
        self.prototypes = nn.Parameter(torch.randn(num_sentiments, hidden_dim))
        self.attention = nn.Linear(hidden_dim, num_sentiments)
    
    def forward(self, entity_repr):
        # Compute similarity to sentiment prototypes
        attn_weights = F.softmax(self.attention(entity_repr), dim=-1)
        
        # Weighted combination of prototypes
        sentiment_context = torch.matmul(attn_weights, self.prototypes)
        
        # Enhance entity representation
        enhanced = entity_repr + sentiment_context
        return enhanced
```

**Expected Gain**: +0.3-0.5%  
**Effort**: Low  
**Risk**: Low

---

### **TIER 2: Medium Impact, Medium Risk** (Expected: +0.8-1.2%)

#### 5. **Multi-Task Learning with Auxiliary Tasks** ‚≠ê‚≠ê
**Problem**: Model only learns from triplet extraction  
**Solution**: Add auxiliary tasks to improve representations

**Auxiliary Tasks**:
1. **Aspect Category Classification** - Predict aspect category (food, service, ambiance)
2. **Opinion Polarity Intensity** - Predict sentiment strength (weak/strong)
3. **Entity Type Prediction** - Explicit vs implicit aspects

**Implementation**:
```python
class MultiTaskHead(nn.Module):
    def __init__(self, hidden_dim):
        self.triplet_head = TripletClassifier(hidden_dim)
        self.category_head = nn.Linear(hidden_dim, num_categories)
        self.intensity_head = nn.Linear(hidden_dim, 3)  # weak/medium/strong
    
    def forward(self, features):
        triplet_logits = self.triplet_head(features)
        category_logits = self.category_head(features)
        intensity_logits = self.intensity_head(features)
        return triplet_logits, category_logits, intensity_logits

# Loss: L_total = L_triplet + 0.3*L_category + 0.2*L_intensity
```

**Expected Gain**: +0.4-0.6%  
**Effort**: High (need auxiliary labels)  
**Risk**: Medium (may need label annotation)

---

#### 6. **Hierarchical Attention (Token ‚Üí Span ‚Üí Sentence)** ‚≠ê‚≠ê
**Problem**: Flat attention doesn't capture hierarchical structure  
**Solution**: Multi-level attention mechanism

**Implementation**:
```python
class HierarchicalAttention(nn.Module):
    def __init__(self, hidden_dim):
        self.token_attention = nn.MultiheadAttention(hidden_dim, 8)
        self.span_attention = nn.MultiheadAttention(hidden_dim, 4)
        self.sentence_attention = nn.Linear(hidden_dim, 1)
    
    def forward(self, token_features):
        # Level 1: Token-level attention
        token_attended, _ = self.token_attention(token_features, token_features, token_features)
        
        # Level 2: Span-level (group tokens into spans)
        span_features = self.group_to_spans(token_attended)
        span_attended, _ = self.span_attention(span_features, span_features, span_features)
        
        # Level 3: Sentence-level
        sentence_weights = F.softmax(self.sentence_attention(span_attended), dim=0)
        sentence_repr = (sentence_weights * span_attended).sum(0)
        
        return span_attended, sentence_repr
```

**Expected Gain**: +0.3-0.5%  
**Effort**: High  
**Risk**: Medium

---

#### 7. **Graph Transformer for Syntactic GCN** ‚≠ê‚≠ê
**Problem**: Current Syntactic GCN underperforms  
**Solution**: Replace with Graph Transformer (attention over graph structure)

**Implementation**:
```python
class GraphTransformer(nn.Module):
    def __init__(self, hidden_dim, num_heads=8, num_layers=2):
        self.layers = nn.ModuleList([
            GraphTransformerLayer(hidden_dim, num_heads) 
            for _ in range(num_layers)
        ])
    
    def forward(self, node_features, adj_matrix):
        x = node_features
        for layer in self.layers:
            x = layer(x, adj_matrix)
        return x

class GraphTransformerLayer(nn.Module):
    def __init__(self, hidden_dim, num_heads):
        self.attention = nn.MultiheadAttention(hidden_dim, num_heads)
        self.ffn = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim * 4),
            nn.GELU(),
            nn.Linear(hidden_dim * 4, hidden_dim)
        )
        self.norm1 = nn.LayerNorm(hidden_dim)
        self.norm2 = nn.LayerNorm(hidden_dim)
    
    def forward(self, x, adj):
        # Masked attention (only attend to neighbors in graph)
        mask = (adj == 0)
        attn_out, _ = self.attention(x, x, x, attn_mask=mask)
        x = self.norm1(x + attn_out)
        
        # FFN
        ffn_out = self.ffn(x)
        x = self.norm2(x + ffn_out)
        return x
```

**Expected Gain**: +0.4-0.7%  
**Effort**: High  
**Risk**: Medium (may need careful tuning)

---

### **TIER 3: Lower Impact, Quick Wins** (Expected: +0.5-0.8%)

#### 8. **Data Augmentation** ‚≠ê
**Problem**: Limited training data (592 samples)  
**Solutions**:
- **Back-translation**: Translate to another language and back
- **Synonym replacement**: Replace words with synonyms
- **Contextual word substitution**: Use BERT to suggest replacements
- **Span perturbation**: Slightly modify span boundaries

**Expected Gain**: +0.3-0.5%  
**Effort**: Low-Medium  
**Risk**: Low

---

#### 9. **Ensemble Methods** ‚≠ê
**Problem**: Single model has limited capacity  
**Solutions**:
- Train 5 models with different random seeds
- Use different architectures (with/without enhancements)
- Voting or weighted averaging

**Expected Gain**: +0.3-0.5%  
**Effort**: Low (just training time)  
**Risk**: Very Low

---

#### 10. **Better Hyperparameter Tuning** ‚≠ê
**Problem**: Current hyperparameters may be suboptimal  
**Solutions**:
- Learning rate scheduling (cosine annealing, warmup)
- Gradient accumulation for larger effective batch size
- Different learning rates for different components (DeBERTa vs GCN)
- Label smoothing for classification

**Expected Gain**: +0.2-0.4%  
**Effort**: Low  
**Risk**: Very Low

---

### **TIER 4: Advanced Techniques** (Expected: +0.5-1%)

#### 11. **Pre-training on Related Tasks** ‚≠ê‚≠ê
**Problem**: Model starts from scratch on ASTE  
**Solution**: Pre-train on related tasks before fine-tuning

**Pre-training Tasks**:
1. Masked Aspect Prediction
2. Sentiment Classification
3. Opinion Term Extraction
4. Aspect-Opinion Pair Matching

**Expected Gain**: +0.4-0.6%  
**Effort**: Very High  
**Risk**: Medium

---

#### 12. **Curriculum Learning** ‚≠ê
**Problem**: Model sees all examples equally  
**Solution**: Train on easy examples first, gradually increase difficulty

**Difficulty Metrics**:
- Number of triplets per sentence
- Span length
- Sentiment ambiguity

**Expected Gain**: +0.2-0.4%  
**Effort**: Medium  
**Risk**: Low

---

## üìã Recommended Implementation Plan

### **Phase 1: Quick Wins (1-2 weeks)** ‚Üí Target: 77.5-78%
1. ‚úÖ Data Augmentation (back-translation, synonym replacement)
2. ‚úÖ Hyperparameter tuning (learning rate schedule, gradient accumulation)
3. ‚úÖ Ensemble 3-5 models with different seeds

**Expected**: 77.14% ‚Üí 77.8% (+0.66%)

---

### **Phase 2: Core Improvements (2-3 weeks)** ‚Üí Target: 78.5-79%
1. ‚úÖ Contrastive Learning for Entity-Opinion Pairing
2. ‚úÖ Span Boundary Refinement Module
3. ‚úÖ Sentiment-Aware Entity Representations

**Expected**: 77.8% ‚Üí 78.8% (+1.0%)

---

### **Phase 3: Architecture Enhancement (3-4 weeks)** ‚Üí Target: 79.5-80%+
1. ‚úÖ Improved TIN Fusion with Cross-Attention
2. ‚úÖ Graph Transformer for Syntactic GCN
3. ‚úÖ Hierarchical Attention

**Expected**: 78.8% ‚Üí 80%+ (+1.2%)

---

### **Phase 4: Advanced (Optional, if needed)** ‚Üí Target: 80%+
1. Multi-Task Learning with Auxiliary Tasks
2. Pre-training on Related Tasks
3. Curriculum Learning

---

## üéØ Specific Code Changes

### **Priority 1: Contrastive Pairing (Highest ROI)**

**File**: `models/D2E2S_Model.py`

```python
# Add to __init__
self.contrastive_encoder = ContrastivePairEncoder(self._emb_dim)

# Add to _forward_train (after entity classification)
entity_reprs = entity_spans_pool  # [batch, num_entities, hidden_dim]
opinion_reprs = ...  # Extract opinion representations similarly

# Compute contrastive loss
contrastive_loss = self.contrastive_encoder(entity_reprs, opinion_reprs)

# Update total loss
total_loss = entity_loss + sentiment_loss + 0.1 * contrastive_loss + batch_loss
```

---

### **Priority 2: Span Boundary Refinement**

**File**: `models/D2E2S_Model.py`

```python
# Add to __init__
self.boundary_refiner = BoundaryRefinement(self._emb_dim)

# Modify _classify_entities
def _classify_entities(self, encodings, h, entity_masks, size_embeddings, args):
    # ... existing code ...
    
    # Refine span representations
    refined_spans = []
    for i in range(entity_masks.shape[1]):
        span_repr = entity_spans_pool[i]
        context = h[i]  # Full sequence context
        refined = self.boundary_refiner(span_repr, context)
        refined_spans.append(refined)
    
    entity_spans_pool = torch.stack(refined_spans)
    
    # Continue with classification...
```

---

### **Priority 3: Cross-Attention Fusion**

**File**: `models/TIN_GCN.py`

```python
# Replace TIN class with:
class TIN(nn.Module):
    def __init__(self, hidden_dim):
        super(TIN, self).__init__()
        self.cross_attention_fusion = CrossAttentionFusion(hidden_dim)
        self.residual_layers = ...  # Keep existing
    
    def forward(self, h_feature, h_syn_ori, h_syn_feature, h_sem_ori, h_sem_feature, adj_sem_ori, adj_sem_gcn):
        # Apply residual layers
        h_syn = self.residual_layer2(h_feature + h_syn_feature)
        h_sem = self.residual_layer4(h_feature + h_sem_feature)
        
        # Cross-attention fusion (instead of concat + LSTM)
        h_fusion = self.cross_attention_fusion(h_sem, h_syn)
        
        return h_fusion
```

---

## üìä Expected Performance Trajectory

| Phase | Improvements | Expected F1 | Cumulative Gain |
|-------|-------------|-------------|-----------------|
| Current | Enhanced SemGCN | 77.14% | --- |
| Phase 1 | Quick wins | 77.8% | +0.66% |
| Phase 2 | Core improvements | 78.8% | +1.66% |
| Phase 3 | Architecture | 80.0% | +2.86% ‚úÖ |
| Phase 4 | Advanced (if needed) | 80.5%+ | +3.36%+ |

---

## ‚ö†Ô∏è Risk Mitigation

### High-Risk Changes:
1. **Graph Transformer** - May need extensive tuning
   - Mitigation: Start with 1-2 layers, gradually increase
   
2. **Multi-Task Learning** - Requires auxiliary labels
   - Mitigation: Use weak supervision or pseudo-labels
   
3. **Cross-Attention Fusion** - May hurt if not tuned properly
   - Mitigation: Keep original TIN as fallback, A/B test

### Testing Strategy:
- Test each improvement independently first
- Combine only after validating individual gains
- Keep baseline model for comparison
- Use validation set to prevent overfitting

---

## üî¨ Ablation Study Plan

After implementing improvements, conduct ablation study:

| Configuration | Expected F1 |
|--------------|-------------|
| Baseline | 77.14% |
| + Contrastive Learning | 77.6% |
| + Span Refinement | 78.0% |
| + Cross-Attention Fusion | 78.5% |
| + Sentiment Prototypes | 78.8% |
| + Graph Transformer | 79.3% |
| + Hierarchical Attention | 79.7% |
| + Ensemble (5 models) | 80.2% ‚úÖ |

---

## üí° Key Insights

### Why These Will Work:

1. **Contrastive Learning** - Directly addresses entity-opinion pairing, which is core to triplet extraction
2. **Span Refinement** - Boundary errors are common in span extraction tasks
3. **Cross-Attention** - Better than simple concatenation for multi-modal fusion
4. **Sentiment Prototypes** - Adds explicit sentiment modeling to entity representations
5. **Ensemble** - Almost always gives 0.3-0.5% boost with minimal risk

### What to Avoid:

1. ‚ùå Adding more GCN layers - Already tried, didn't help
2. ‚ùå Larger models (DeBERTa-large) - OOM issues, diminishing returns
3. ‚ùå Complex fusion mechanisms without validation - High risk, uncertain gain
4. ‚ùå Too many auxiliary tasks - May dilute main task learning

---

## üéâ Success Criteria

### Minimum Viable Improvement (MVI):
- **Target**: 79% Triplet F1 (+1.86%)
- **Timeline**: 4-6 weeks
- **Confidence**: High (80%)

### Stretch Goal:
- **Target**: 80.5% Triplet F1 (+3.36%)
- **Timeline**: 6-8 weeks
- **Confidence**: Medium (60%)

### Validation:
- Test on all 4 datasets (14res, 14lap, 15res, 16res)
- Ensure improvements generalize across domains
- Maintain or improve Entity F1 score

---

## üìö References & Inspiration

1. **Contrastive Learning**: SimCLR, MoCo approaches adapted for NLP
2. **Span Refinement**: SpanBERT, boundary-aware models
3. **Cross-Attention**: BERT cross-attention, Vision Transformers
4. **Graph Transformers**: Graphormer, Graph-BERT
5. **Multi-Task Learning**: MT-DNN, ERNIE

---

**Next Steps**: 
1. Implement Priority 1 (Contrastive Learning) first
2. Validate on validation set before full training
3. Document results and iterate

**Last Updated**: January 5, 2026, 22:02 IST
